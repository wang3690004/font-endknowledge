###ASCII Unicode GBK UTF-8 之间的关系

#### 1. 二进制位和字节

在计算机世界里 所有信息都是二进制的值(计算机只能识别出 0 和 1) 而我们人类不同有各种各样的语言和文字，这时我们需要讲各种语言文字转换成二进制位来让计算机识别想要表达的内容。

> 我们怎样将其转化为二进制存储到计算机中这个过程我们称为编码。更广义的讲 就是把信息从一种形式转化为另一种形式的过程

我们知道一个二进制位(bit)有 0 和 1 两种状态,因此八个二进制位就可以组合成 256 种状态 这个也被称为一个字节(bit)。 一个字节八位 也就是说是一个字节可以用来表示 256 种不同的状态，每一个状态对应一个符号，就是 256 个符号，从 00000000 到 11111111

#### 2. 基础 ASCII 码

上个世纪 60 年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被成为 ASCII 码 一直沿用至今
ASCII 码一共规定了 128 个字符的编码，比如空格 SPACE 是 32(00100000)。大写字母 A 是 65(01000001)
一个字节 256 位 ASCII 128 位 刚好 第八位空出来 设定最高位为 0

> 0-31 及 127(共 33 个) 是控制字符或通信专用字符如
> 控制符：LF(换行) CR(回车) DEL(删除)
> 通信专用字符： SOH(文头) ACK(确认)等

> 32-126(共 95)个 是可显示字符 其中
> 32 是空格
> 48-57 为 0-9 十个阿拉伯数字
> 65-90 26 个大写字母
> 97-122 为 26 个小写字母
> 其余就是一些标点符号运算符号等

#### 3. 扩展 ASCII 码

在美国这 128 个字符是够用了，但是其他国家不行啊，他们的字符和英文是有出入的，比如法语 汉语 韩语 日语等，特别是汉语文字数量庞大 根本不够用的。
所以各个国家就想了一个办法 决定把字节最高位没有用到的那一位拿来使用，原来的 128 种状态就变成了 256 种状态 并且为了保持与 ASCII 的兼容性，一般最高位为 0 时和 ASCII 码相同,最高位为 1 的时候 各个国家自己给后面的位(1xxx xxxx)赋予了自己国家的字符意义
但是这里又有一个问题，不同的国家有不同的字母，哪怕他们都使用 256 个符号的编码方式，代表的字母却不一样。
比如 130 在法语编码中代表了 é，在希伯来语编码中却代表了字母 Gimel (ג)，在俄语编码中又会代表另一个符号

但是不管怎样，所有这些编码方式种，0-127 肯定都是一致的 不一样的是 128-255 这一段。不同的国家有不同字符集，所以 都不是国际标准。

至于亚洲国家的文字，使用的符号可太多了，汉字就有 10w 多个 包括简体繁体古体等。一个字节只能表示 256 种符号,肯定是不够的 就必须使用多个字节表达一个符号。

#### 4. GBK 和 GB2321

由于 ASCII 码不支持中文，因此当中国人用到计算机时 就需要寻求一种编码方式来支持中文。
于是国人就定义了一套编码规则：当字符小于 127 位时，与 ASCII 字符相同 但当两个大于 127 的字符连接在一起时，就代表一个汉字，第一个字节称为高字节(0xA1-0xF7),第二个字节成为低字节(0xA1-0xFE),这样大约可以组合 7000 多个简体汉字 这个规则就叫做 GB2312

但是由于中国汉字很多，有些字依旧无法表示，于是重新定义了规则： 不在要求低字节一定是 127 之后的编码,只要第一个字节是大于 127,就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里面的内容。

这种扩展方案就叫做 GBK 标准，他包含了 GB2312 的所有内容, 同时新增了近 2000 个汉字(包括繁体字)

#### 5. Unicode

正如上一节所说,世界上存在着多种编码方式, 同一个二级制数字可以被解释成不同的符号,因此想要打开一个文本文件，就必须要知道他的编码方式，否则用错误的编码方式解读就会乱码。

可以想象，如果有一种编码,将世界上所有的符号都纳入其中，每一个符号都有其独一无二的编码，那么乱码问题就会消失，这就是 unicode,就像他的名字一样 "独一无二的 code"
unicode 为世界上所有的字符都分配了一个唯一的数字编号，这个编号范围从 0x00 0000 到 0x10 FFFF(十六进制)有 110W 个 每一个字符都有唯一的编号,这个编号一般写成 16 进制,在前面加上 u+  例如: u+0639 表示阿拉伯字母Ain,u+0041表示英语的大写字母A,U+4e25表示汉字"严"。
unicode 就相当于建立一张表，建立了字符与编号之间的联系,他是一种规定,但是unicode本身只规定了每个字符的数字编号是多少,并没有规定这个编号要如何存储。
比如 汉字"严"的unicode是十六进制4e25 转换成二进制足足有15位(100111000100101),也就是说 这个符号表示至少需要两个字节,表示其他更大的符号 可能要三个甚至四个字节。

这里就有两个严重的问题
1. 如何才能区别 Unicode和ASCII? 计算机怎么知道三个字节表示一个符号而不是三个符号呢？
2. 英文字母只用一个字节就够了,如果unicode统一规定,每个符号用三个或者四个字节来表示,那么每个英文字母前面都必然有两个或者三个字节 是"全零状态"，就是完全浪费了这部分空间了。文本文件会变大很多 这是无法接受的。

他们造成的结果就是:
1. 出现了unicode 的多种存储方式，也就是说有许多不同的二进制格式，可以用来表示unicode
2. unicode 在很长一段时间内无法推广, 直到互联网的出现

#### 6. utf-8
由于互联网的普及,强烈需求产生一个统一的编码方式, UTF-8 就是在互联网上使用最广的一种unicode实现方式，其他的还有utf-16(字符用两个字节或四个字节表示) utf-32(字符用四个字节表示),不过在互联网上基本不用。 
注意： utf-8是unicode的呈现方式之一

UTF-8最大的一个特点 就是他是一种灵活变长的编码方式,他可以用1-4个字节表示一个符号,根据不同的符号而变化字节长度
UTF-8的规则有两条：
1. 对于单字节的符号，字节的第一位设为0，后面七位为这个符号的unicode编码，因此对于英文字母，utf-8编码和ASCII 码是相同的
2. 对于n字节的符号(n>1),第一个字节前n位都设为1，第n+1位为0，后面字节的前两位一律设置为10,剩下的没有提及的二进制位,全部为这个符号的unicode码




意识到以前的一个错误 "默认认为一个英文字符占用一个字节 汉字占用两个字节，实际上不是 汉字可能占用两个或者三个字节"

二进制-> 十进制 十进制->二进制
二进制-> 十六进制 十六进制 -> 二进制
十进制 -> 十六进制 十六进制 -> 十进制

http://www.dedenotes.com/html/unicode-utf-8.html
